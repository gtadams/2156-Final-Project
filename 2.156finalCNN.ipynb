{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1675f8af",
   "metadata": {},
   "source": [
    "**2.156 Final Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864f8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c300b",
   "metadata": {},
   "source": [
    "Load Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02fc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c457e2",
   "metadata": {},
   "source": [
    "We will want to visualize the data next but will add that in when data is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00525a8",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc38286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=288, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=75, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):  # Define all the layers here\n",
    "        super(CNN, self).__init__()\n",
    "        # All pooling will use 2x2 window and stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # First Conv layer: 3 input channel (RBG), 4 output channels, kernel size 3x3, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Second Conv layer: 4 input channels, 8 output channels\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Third Conv layer: 8 input channels, 16 output channels\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Fourth Conv layer: 16 input channels, 32 output channels\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Operation to flatten the images into a vector\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 16)  # Adjusted to match the output size after conv3\n",
    "        self.fc2 = nn.Linear(16, 75)  # 75 output classes??\n",
    "        #WILL NEED TO EDIT based on number of parts we decide on\n",
    "\n",
    "    def forward(self, x):  # Call all the layers in this function\n",
    "        # Reshape the input to ensure it has the correct channel dimension: [batch x 1 x 50 x 50]\n",
    "        if len(x.shape) == 3:  # Input is [batch x 50 x 50]\n",
    "            x = x.unsqueeze(1)  # Add channel dimension -> [batch x 1 x 50 x 50]\n",
    "\n",
    "        # Convolve, then pass through ReLU, then pooling\n",
    "        x = F.relu(self.conv1(x))  # [batch x 4 x 50 x 50]\n",
    "        x = self.pool(x)  # [batch x 4 x 25 x 25]\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # [batch x 8 x 25 x 25]\n",
    "        x = self.pool(x)  # [batch x 8 x 12 x 12]\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # [batch x 16 x 12 x 12]\n",
    "        x = self.pool(x)  # [batch x 16 x 6 x 6]\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # [batch x 32 x 6 x 6]\n",
    "        x = self.pool(x)  # [batch x 32 x 3 x 3]\n",
    "\n",
    "        x = self.flatten(x)  # Flatten for the fully connected layer [batch x 288]\n",
    "\n",
    "        # Pass through fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))  # [batch x 16]\n",
    "\n",
    "        # Final fully connected layer with no activation (since we are doing regression)\n",
    "        x = self.fc2(x)  # Output layer with 5 outputs [batch x 5]\n",
    "        return x\n",
    "\n",
    "# Create a CNN model instance\n",
    "model_cnn = CNN()\n",
    "model_cnn.to(device)\n",
    "\n",
    "# Print the model's architecture\n",
    "#summary(model_cnn, input_size=(1, 50, 50))  # Adjusted input size for grayscale images with 1 channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efaba38",
   "metadata": {},
   "source": [
    "Create Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a95551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train, X_validation, Y_validation, num_epochs=10, batch_size=32, learning_rate=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Function to train a given model (CNN or DNN) using training and validation data.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to train (e.g., CNN or DNN).\n",
    "    - X_train: Training data (features).\n",
    "    - Y_train: Training data (labels).\n",
    "    - X_validation: Validation data (features).\n",
    "    - Y_validation: Validation data (labels).\n",
    "    - num_epochs: Number of training epochs (default: 10).\n",
    "    - batch_size: Batch size for training (default: 32).\n",
    "    - learning_rate: Learning rate for the optimizer (default: 0.001).\n",
    "    - device: Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - train_losses: List of training losses for each epoch.\n",
    "    - val_losses: List of validation losses for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Move model to the specified device (GPU or CPU)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function (Mean Squared Error for regression tasks)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Define optimizer (Adam optimizer with specified learning rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Create DataLoader for batching the training data\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create DataLoader for batching the validation data\n",
    "    validation_dataset = TensorDataset(torch.tensor(X_validation, dtype=torch.float32), torch.tensor(Y_validation, dtype=torch.float32))\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Lists to store train and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Using tqdm for the training loop progress bar\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch [{epoch + 1}/{num_epochs}]', leave=False)\n",
    "\n",
    "        # Iterate over batches of training data\n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs = inputs.to(device)  # Move inputs to device (GPU/CPU)\n",
    "            labels = labels.to(device)  # Move labels to device (GPU/CPU)\n",
    "\n",
    "            # Zero the gradients before the next update\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute model outputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform a single optimization step (update model parameters)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss over the batch\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Update tqdm progress bar with current loss\n",
    "            train_loader_tqdm.set_postfix({'Train Loss': running_loss / len(train_loader.dataset)})\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Validation loop (no gradient computation)\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass: compute model outputs\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute validation loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate average validation loss for the epoch\n",
    "        val_loss /= len(validation_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Print the train and validation loss at the end of each epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Train MSE: {epoch_loss:.4f} - Validation MSE: {val_loss:.4f}')\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Return the recorded training and validation losses\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c1d53",
   "metadata": {},
   "source": [
    "Plot Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    Function to plot the training and validation loss convergence over epochs.\n",
    "\n",
    "    Args:\n",
    "    - train_losses: List of training losses per epoch.\n",
    "    - val_losses: List of validation losses per epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.plot(train_losses, label='Train Mean Squared Error (MSE)', color=\"black\")\n",
    "    plt.plot(val_losses, label='Validation Mean Squared Error (MSE)', color=\"red\")\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # Add legend in the upper right corner\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Remove the top and right borders\n",
    "    ax = plt.gca()  # Get the current axis\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db7fdd",
   "metadata": {},
   "source": [
    "Plot Predictions With R-squared: scatterplots to compare our model's predicted values with the ground truth values from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b4e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_r2(model, X_validation, Y_validation, X_test, Y_test, device, names=None, show_test=True):\n",
    "    \"\"\"\n",
    "    Function to plot actual vs predicted values for validation and optionally test datasets,\n",
    "    display R² scores in the subplot titles, and add a legend in the last (unused) subplot.\n",
    "\n",
    "    Args:\n",
    "    - model: The trained model (DNN or CNN) used for making predictions.\n",
    "    - X_validation: Validation feature data.\n",
    "    - Y_validation: Validation target data.\n",
    "    - X_test: Test feature data.\n",
    "    - Y_test: Test target data.\n",
    "    - device: The device (GPU or CPU) on which the model is running.\n",
    "    - names: List of names for the target variables (default: None).\n",
    "    - show_test: Boolean flag to control whether to show test data or only validation data (default: True).\n",
    "    \"\"\"\n",
    "\n",
    "    if names is None:\n",
    "        names = [\"C11\", \"C12\", \"C22\", \"C66\", \"Volume Fraction\"]  # Default names for target variables\n",
    "\n",
    "    # Generate predictions for the validation and test sets\n",
    "    val_pred = model(torch.tensor(X_validation, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "\n",
    "    if show_test:\n",
    "        test_pred = model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "\n",
    "    # Create a figure with 2x3 subplots (6 in total)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "    # Loop over the target variables (assuming 5 here)\n",
    "    for i in range(5):\n",
    "        # Calculate the R² score for validation and test sets\n",
    "        r2_val = r2_score(Y_validation[:, i], val_pred[:, i])\n",
    "\n",
    "        if show_test:\n",
    "            r2_test = r2_score(Y_test[:, i], test_pred[:, i])\n",
    "\n",
    "        # Plot actual vs predicted for validation (and optionally test) sets\n",
    "        ax = axs[i // 3, i % 3]  # Subplot position\n",
    "\n",
    "        if show_test:\n",
    "            # Plot test data if the flag is set to True\n",
    "            ax.scatter(Y_test[:, i], test_pred[:, i], s=3, color=\"#32a895\", alpha=0.2, label='Test')\n",
    "\n",
    "            # Plot the ideal 1:1 line (using ranges from test)\n",
    "            ax.plot([min(test_pred[:, i]), max(test_pred[:, i])],\n",
    "                    [min(test_pred[:, i]), max(test_pred[:, i])], color='#f73946', linestyle='--', label='Target Line')\n",
    "        else:\n",
    "            # Plot the ideal 1:1 line (using ranges from val)\n",
    "            ax.plot([min(val_pred[:, i]), max(val_pred[:, i])],\n",
    "                    [min(val_pred[:, i]), max(val_pred[:, i])], color='#f73946', linestyle='--', label='Target Line')\n",
    "\n",
    "        # Plot validation data\n",
    "        ax.scatter(Y_validation[:, i], val_pred[:, i], s=3, color=\"black\", alpha=0.2, label='Validation')\n",
    "\n",
    "        # Set labels for the axes\n",
    "        ax.set_xlabel(f\"Actual {names[i]}\")\n",
    "        ax.set_ylabel(f\"Predicted {names[i]}\")\n",
    "\n",
    "        # Add the R² scores to the title of each subplot\n",
    "        if show_test:\n",
    "            ax.set_title(f\"{names[i]} - R² Val: {r2_val:.2f}, R² Test: {r2_test:.2f}\")\n",
    "        else:\n",
    "            ax.set_title(f\"{names[i]} - R² Val: {r2_val:.2f}\")\n",
    "\n",
    "        # Remove the top and right borders for a cleaner look\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "    # Add legend in the last subplot (bottom right, unfilled one)\n",
    "    axs[1, 2].axis('off')  # Turn off the empty subplot\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from previous plots\n",
    "\n",
    "    # Make points in the legend larger by adjusting 'scatterpoints' and 'markerscale'\n",
    "    axs[1, 2].legend(handles, labels, loc='center', scatterpoints=3, markerscale=4, handletextpad=1.5)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
